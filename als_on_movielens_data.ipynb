{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.recommendation import ALS, Rating\n",
    "from pyspark.mllib.evaluation import RegressionMetrics, RankingMetrics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data...\n",
      "Ratings : \n",
      "[Rating(user=1, product=1, rating=4.0), Rating(user=1, product=3, rating=4.0), Rating(user=1, product=6, rating=4.0)]\n",
      "Ratings chosen: \n",
      "[Rating(user=1, product=157, rating=5.0), Rating(user=1, product=216, rating=5.0), Rating(user=1, product=231, rating=5.0)]\n",
      "Testset : \n",
      "[(1, 157), (1, 216), (1, 231)]\n",
      "\n",
      "Training recommendation model...\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def parseline(line):\n",
    "    fields = line.split(',')\n",
    "    userId = fields[0]\n",
    "    movieId = fields[1]\n",
    "    rating = fields[2]\n",
    "    return (userId, movieId, rating)\n",
    "\n",
    "def loadMovieInfo():\n",
    "    moviesNames = {}\n",
    "    data_frame = pd.read_csv(\"res/sample/movies.csv\")\n",
    "    for index, row in data_frame.iterrows():\n",
    "        moviesNames[int(row[\"movieId\"])] = row[\"title\"]\n",
    "            \n",
    "    return moviesNames\n",
    "\n",
    "movieNames = loadMovieInfo()\n",
    "    \n",
    "# pyspark set-up\n",
    "sc.setCheckpointDir('checkpoint')\n",
    "\n",
    "# Build rating object for ALS \n",
    "print(\"\\nLoading data...\")\n",
    "\n",
    " \n",
    "lines = sc.textFile(\"res/sample/ratings.csv\")\n",
    "parsedlines = lines.map(parseline)\n",
    "header = parsedlines.first()\n",
    "\n",
    "#filter out the header, make sure the rest looks correct\n",
    "parsedlines = parsedlines.filter(lambda line: line != header)\n",
    "\n",
    "ratings = parsedlines.map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])) ).cache()\n",
    "print(f\"Ratings : \\n{ratings.take(3)}\")\n",
    "\n",
    "test, train = ratings.randomSplit(weights=[0.2, 0.8], seed=1)\n",
    "print(f\"Ratings chosen: \\n{test.take(3)}\")\n",
    "\n",
    "testset = test.map(lambda t: (t[0], t[1]))\n",
    "print(f\"Testset : \\n{testset.take(3)}\")\n",
    "\n",
    "# Build the recommendation model using Alternating Least Squares\n",
    "print(\"\\nTraining recommendation model...\")\n",
    "rank = 5\n",
    "numIterations = 20\n",
    "model = ALS.train(train, rank, numIterations)\n",
    "\n",
    "predictions = model.predictAll(testset).collect()\n",
    "#print(f\"Predictions : \\n{predictions}\")\n",
    "\n",
    "embedding = model.userFeatures().collect()\n",
    "print(\"\\nDone!\")\n",
    "\n",
    "\n",
    "#output recommendations to file\n",
    "prediction_with_movie_names = []\n",
    "\n",
    "for userId,movieId,rating in predictions:\n",
    "    prediction_with_movie_names.append(movieNames[movieId])\n",
    "\n",
    "pred_df = pd.DataFrame(predictions)\n",
    "pred_df['title'] = pd.Series(prediction_with_movie_names)\n",
    "pred_df = pred_df[['user','product', 'title', 'rating']]\n",
    "pred_df.to_csv(\"als_predictions.csv\", index=False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_rating = pd.DataFrame(test.collect()).sort_values(by=['user','rating'],\n",
    "                                                       ascending=[True,False]).reset_index()['rating']\n",
    "\n",
    "pred_df = pred_df.sort_values(by=['user','rating'],\n",
    "                              ascending=[True,False]).reset_index()\n",
    "\n",
    "pred_df['true'] = true_rating\n",
    "\n",
    "pred_df = pred_df[['user','product','rating','true']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "\n",
    "    ini = defaultdict(list)\n",
    "    top_n = defaultdict(list)\n",
    "    \n",
    "    for uid, iid, est in predictions:\n",
    "        ini[uid].append((iid, est))\n",
    "        \n",
    "    for uid, iid, true in test.collect():\n",
    "        for i in [x[0] for x in ini[uid]]:\n",
    "            if iid == i:\n",
    "                top_n[uid].append(ini[uid][[x[0] for x in ini[uid]].index(iid)]+(true,))\n",
    "                \n",
    "    #uid:[(iid,est),(iid,est)]\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings#[:n]\n",
    "    return top_n\n",
    "\n",
    "top_n = get_top_n(predictions, n=10)\n",
    "users_est = defaultdict(list)\n",
    "users_true=defaultdict(list)\n",
    "\n",
    "for uid, user_ratings in top_n.items():\n",
    "    users_est[uid].append([est for (_, est,_) in user_ratings])\n",
    "    users_true[uid].append([true_r for (_,_,true_r) in user_ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg(y_true, y_pred, k=None, powered=False):\n",
    "    def dcg(scores, k=None, powered=False):\n",
    "        if k is None:\n",
    "            k = scores.shape[0]\n",
    "        if not powered:\n",
    "            ret = scores[0]\n",
    "            for i in range(1, k):\n",
    "                ret += scores[i] / np.log2(i + 1)\n",
    "            return ret\n",
    "        else:\n",
    "            ret = 0\n",
    "            for i in range(k):\n",
    "                ret += (2 ** scores[i] - 1) / np.log2(i + 2)\n",
    "            return ret\n",
    "    \n",
    "    ideal_sorted_scores = np.sort(y_true)[::-1]\n",
    "    ideal_dcg_score = dcg(ideal_sorted_scores, k=k, powered=powered)\n",
    "    \n",
    "    pred_sorted_ind = np.argsort(y_pred)[::-1]\n",
    "    pred_sorted_scores = y_true[pred_sorted_ind]\n",
    "    dcg_score = dcg(pred_sorted_scores, k=k, powered=powered)\n",
    "    \n",
    "    return dcg_score / ideal_dcg_score\n",
    "\n",
    "def ndcg1(y_true, y_pred, k=None):\n",
    "    return ndcg(y_true, y_pred, k=k, powered=False)\n",
    "\n",
    "def ndcg2(y_true, y_pred, k=None):\n",
    "    return ndcg(y_true, y_pred, k=k, powered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NDCG(10) = 0.9478173654283814\n"
     ]
    }
   ],
   "source": [
    "ndcg_list=[]\n",
    "for uid in top_n:\n",
    "    \n",
    "    for i in users_true[uid]:\n",
    "        y_true=np.asarray(i)#.reshape(-1,1)\n",
    "    \n",
    "    for i in users_est[uid]:\n",
    "        y_pred=np.asarray(i)#.reshape(-1,1)\n",
    "        ndcg_list.append(ndcg1(y_true, y_pred, k=None))\n",
    "        \n",
    "ndcg_list = [i for i in ndcg_list if str(i) != 'nan']\n",
    "print(\"\\nNDCG(10) = %s\" % str(sum(ndcg_list)/len(ndcg_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    MAP = AP/mydf['user'].nunique()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# MAP\n",
    "threshold = 8\n",
    "pred_df['relevant'] = np.where(pred_df['true'] > threshold, 1,0)\n",
    "pred_df['recommended'] = np.where(pred_df['rating'] > threshold, 1,0)\n",
    "def MAP_k(mydf, k=5):\n",
    "    \n",
    "    AP = 0.0\n",
    "    for i in mydf['user'].unique():\n",
    "        #print(\"user is\", i)\n",
    "        user_df = mydf[mydf['user'] == i]\n",
    "        user_df.sort_values('rating', axis=0, inplace=True, ascending=False)\n",
    "        top_N_items = user_df['recommended'].values[:k+1]\n",
    "       \n",
    "        #print(\"top items\", top_N_items )\n",
    "        p_list = np.empty((0,k), int)\n",
    "        for j in range(len(top_N_items)):\n",
    "            l = user_df['recommended'].values[:j+1]\n",
    "            val = np.sum(l)/len(l)\n",
    "            p_list = np.append(p_list, val)\n",
    "       \n",
    "        #print(\"List is\",p_list)\n",
    "        sum_val = sum(p_list * top_N_items)\n",
    "        if(sum(user_df['relevant'] >0)):\n",
    "           AP = AP + sum_val/sum(user_df['relevant'])\n",
    "        \n",
    "   MAP = AP/mydf['user'].nunique()\n",
    "   return MAP\n",
    "\n",
    "MAP_k(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCalculating Test RMSE...\")\n",
    "testData = test.map(lambda p: (p.user, p.product))\n",
    "predictions = model.predictAll(testData).map(lambda r: ((r.user, r.product), r.rating))\n",
    "ratingsTuple = test.map(lambda r: ((r.user, r.product), r.rating))\n",
    "scoreAndLabels = predictions.join(ratingsTuple).map(lambda tup: tup[1])\n",
    "\n",
    "metrics_rating = RegressionMetrics(scoreAndLabels)\n",
    "print(f\"\\nTest RMSE = {metrics_rating.rootMeanSquaredError}\")\n",
    "print(f\"\\nTest MAE = {metrics_rating.meanAbsoluteError}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark in Python 3",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
